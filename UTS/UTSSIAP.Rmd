---
title: "SYNTAX FOR UTS MPDW"
author: "Adisti Suci Rahmah"
date: "2023-10-05"
output: html_document
---

### SMA 
```{r}
library("forecast")
library("TTR")
library("graphics")
Data1<-read.csv("D:/campus/work/BahanMandiri/Moving Average.csv", 
header=TRUE)
#membentukobjektime  series
Data1.ts<-ts(Data1)  
#melakukanSingle Moving  Average dengann=3
Data1.sma<-SMA(Data1.ts,  n=3)
ramal.sma<-c(NA,Data1.sma)
Data<-cbind(bagihasil_aktual=c (Data1.ts,NA),pemulusan=c 
(Data1.sma,NA),ramal.sma)
```

```{r}
#membuatplot 
ts.plot(Data1.ts,xlab="periodewaktu",ylab="Bagihasil",  
col="blue",lty=3)
points(Data1.ts)
lines (Data1.sma,col="red",lwd=2)
lines (ramal.sma,col="black",lwd= 2)
title("RataanbergerakSederhanan=3",cex.main=1,font.main=4 
,col.main="black")
legend(locator(1),legend=c ("Data aktual","Pemulusan
 SMA","RamalanSMA"),lty=1:3,col=c ("blue","red","black"))
```

### MENCARI NILAI KEAKURATAN
### MAPE
```{r}
#menghitung nilai keakuratan
error<-Data1.ts-ramal.sma[1:length(Data1.ts)]
MAPE<
mean(abs((error[4:length(Data1.ts)]/ramal.sma[4:length(Data1.ts)])*100))
```

## DMA
```{r}
bagihasil.dma<-SMA(Data1.sma,n=3)
At<-2*Data1.sma-bagihasil.dma
Bt<-Data1.sma-bagihasil.dma
pemulusan.dma<-At+Bt
ramal.dma<-c(NA,pemulusan.dma)
Data.dma<
cbind(bagihasil_aktual=c(Data1.ts,NA),pemulusan.dma=c(pemulusan.dma,NA),ramal.dma)
```

```{r}
#membuatplot
ts.plot(Data1.ts,xlab="periodewaktu",ylab="Bagi
hasil",  col="blue",lty=3)
points(Data1.ts)
lines (pemulusan.dma,col="red",lwd=2)
lines (ramal.dma,col="black",lwd= 2)
title("RataanbergerakBerganda
n=3",cex.main=1,font.main=4 ,col.main="black")
legend(locator(1),legend=c ("Data 
aktual","Pemulusan","Ramalan"),lty=1:3,col=c 
("blue","red","black"))
```

## PERBANDINGAN SMA DAN DMA
```{r}
 #perbandinganSMA danDMA
 ts.plot(Data1.ts,xlab="periodewaktu",ylab="Bagi
 hasil",  col="blue",lty=3)
 points(Data1.ts)
 lines (pemulusan.dma,col="red",lwd=2)
 lines (Data1.sma,col="black",lwd= 2)
 title("PerbandinganSMA dan
 DMA",cex.main=1,font.main=4 ,col.main="black")
 legend(locator(1),legend=c ("Data 
aktual","PemulusanSMA","Pemulusan
 DMA"),lty=1:3,col=c ("blue","black","red")
```

### Model Koyck
```{r}
 install.packages("dLagM")
 library("dLagM")
 01
 02
 data<-read.delim("clipboard")
 model.koyck=koyckDlm(x=data$Xt, y=data$Yt)
```

---
title: "Pertemuan 2 - Regresi"
author:
- Adelia Putri Pangestika
- Muhammad Rizky Nurhambali
output:
  html_document:
    theme: yeti
    toc: true
    toc_float: true
  word_document: default
  pdf_document: default
---

## Pemanggilan *Packages*

```{r}
library(dplyr)
library(TTR)
library(forecast)
library(lmtest) #digunakan untuk uji formal pendeteksian autokorelasi
library(orcutt) #untuk membuat model regresi Cochrane-Orcutt
library(HoRM) #untuk membuat model regresi Hildreth-Lu
```

## Input Data

Data yang digunakan dalam kesempatan kali ini adalah data IPM Provinsi Gorontalo periode tahun 2010-2021.

```{r}
tahun <- c(2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021)
ipm <- c(62.65,63.48,64.16,64.70,65.17,65.86,66.29,67.01,67.71,68.49,68.68,69.00)
dtGorontalo <- cbind(tahun,ipm)
dtGorontalo <- as.data.frame(dtGorontalo)
dtGorontalo
```

## Eksplorasi Data

Sebelum melakukan regresi, akan diperlihatkan *plot time-series* dari IPM Provinsi Gorontalo Periode 2010-2021

```{r}
#Membentuk objek time series
data.ts<-ts(dtGorontalo$ipm)
data.ts

#Membuat plot time series
ts.plot(data.ts, xlab="Time Period ", ylab="IPM", main= "Time Series Plot of IPM")
points(data.ts)
```

Selanjutnya akan dilakukan ramalan dan pemulusan dengan metode DMA dan DES karena terlihat pada plot di atas menunjukkan adanya *trend*.

```{r}
dt.sma <- SMA(data.ts, n=6)
dma <- SMA(dt.sma, n = 6)
At <- 2*dt.sma - dma
Bt <- 2/(4-1)*(dt.sma - dma)
dt.dma<- At+Bt
dt.ramal<- c(NA, dt.sma)

t = 1:5
f = c()

for (i in t) {
  f[i] = At[length(At)] + Bt[length(Bt)]*(i)
}
```

```{r}
dt.gab <- cbind(aktual = c(data.ts,rep(NA,5)), 
                pemulusan1 = c(dt.sma,rep(NA,5)),
                pemulusan2 = c(dt.dma, rep(NA,5)),
                At = c(At, rep(NA,5)), 
                Bt = c(Bt,rep(NA,5)),
                ramalan = c(dt.ramal, f[-1]))
dt.gab

#Plot time series
ts.plot(dt.gab[,1], xlab="Time Period ", ylab="IPM", 
        main= "DMA N=6 Data IPM", ylim=c(62,75))
points(dt.gab[,1])
points(dt.gab[,3])
points(dt.gab[,6])
lines(dt.gab[,3],col="green",lwd=2)
lines(dt.gab[,6],col="red",lwd=2)
legend("topleft",c("data aktual","data pemulusan","data peramalan"), 
       lty=8, col=c("black","green","red"), cex=0.8)
```

Selanjutnya akan dilihat keakuratan dari metode DMA

```{r}
#Menghitung nilai keakuratan
error.dma = data.ts-dt.ramal[1:length(data.ts)]
SSE.dma = sum(error.dma[7:length(data.ts)]^2)
MSE.dma = mean(error.dma[7:length(data.ts)]^2)
MAPE.dma = mean(abs((error.dma[7:length(data.ts)]/data.ts[7:length(data.ts)])*100))

akurasi.dma <- matrix(c(SSE.dma, MSE.dma, MAPE.dma))
row.names(akurasi.dma)<- c("SSE", "MSE", "MAPE")
colnames(akurasi.dma) <- c("Akurasi m = 6")
akurasi.dma
```

Selanjutnya akan digunakan metode *Double Exponential Smoothing* dengan cara sebagai berikut.

Pertama akan data akan dibagi menjadi data *training* dan data *testing*.

```{r}
#membagi training dan testing
training<-dtGorontalo[1:10,2]
testing<-dtGorontalo[11:12,2]

#data time series
training.ts<-ts(training)
testing.ts<-ts(testing,start=11)

#eksplorasi data
par(nfrow=c(1,2))
plot(data.ts, col="red",main="Plot semua data")
points(data.ts)

plot(training.ts, col="blue",main="Plot semua data")
points(training.ts)
```

Selanjutnya akan dilakukan pemulusan dengan DES, kali ini langsung dicari lambda dan gamma optimum sebagai berikut. Nilai lambda dan gamma optimum dapat dilihat pada smoothing parameters alpha untuk nilai lambda dan beta untuk nilai gamma.

```{r}
#Lamda dan gamma optimum
des.opt<- HoltWinters(training.ts, gamma = FALSE)
des.opt
plot(des.opt)
legend("topleft", c("Data Aktual", "Peramalan"), col = c("black", "red"), 
       lty = c(1,1))


#ramalan
ramalandesopt<- forecast(des.opt, h=5)
ramalandesopt
```

Selanjutnya akan dicari akurasi dari metode DES.

```{r}
ssedes.train<-des.opt$SSE
msedes.train<-ssedes.train/length(training.ts)
sisaandes<-ramalandesopt$residuals
head(sisaandes)

mapedes.train <- sum(abs(sisaandes[3:length(training.ts)]/training.ts[3:length(training.ts)])*100)/length(training.ts)

akurasides.opt <- matrix(c(ssedes.train,msedes.train,mapedes.train))
row.names(akurasides.opt)<- c("SSE", "MSE", "MAPE")
colnames(akurasides.opt) <- c("Akurasi lamda dan gamma optimum")
akurasides.opt
```

```{r}
#Akurasi data testing
selisihdesopt<-ramalandesopt$mean-testing.ts
selisihdesopt

SSEtestingdesopt<-sum(selisihdesopt^2)
SSEtestingdesopt<-SSEtestingdesopt/length(testing.ts)
MAPEtestingdesopt<-sum(abs(selisihdesopt/testing.ts)*100)/length(testing.ts)

akurasiDesTesting <- matrix(c(SSEtestingdesopt,SSEtestingdesopt,MAPEtestingdesopt))
row.names(akurasiDesTesting)<- c("SSE", "MSE", "MAPE")
colnames(akurasiDesTesting) <- c("Akurasi lamda dan gamma optimum")
akurasiDesTesting
```

Setelah didapatkan nilai akurasi untuk metode DMA dan DES, selanjutnya akan dibandingkan keakuratan antar metode keduanya.

```{r}
cbind(akurasi.dma, akurasiDesTesting)
```

Berdasarkan perbandingan akurasi tersebut, terlihat nilai SSE, MSE, dan MAPE metode DES lebih kecil dibandingkan dengan metode DMA. Oleh karena itu, metode peramalan dan pemulusan yang terbaik antara keduanya adalah dengan metode DES.

Setelah melakukan peramalan, data yang telah dimasukkan kemudian dieksplorasi. Eksplorasi pertama yang dilakukan adalah dengan menggunakan *scatter plot*.

```{r}
#Eksplorasi Data
#Pembuatan Scatter Plot
plot(tahun,ipm, pch = 20, col = "blue",
     main = "Scatter Plot Tahun vs Nilai IPM",
     xlab = "Tahun",
     ylab = "Nilai IPM")
#Menampilkan Nilai Korelasi
cor(tahun,ipm)
```

Berdasarkan scatter plot di atas, terlihat adanya hubungan / korelasi positif antara peubah tahun dengan nilai IPM, terlihat titik-titik pada plot yang naik ke arah kanan atas. Hal tersebut juga diperkuat dengan hasil perhitungan aplikasi `R` di mana didapatkan nilai korelasi sebesar $0.9966848$.

Setalah mengetahui adanya hubungan antar dua peubah, maka model regresi dapat ditentukan.

## Regresi

```{r}
#Pembuatan Model Regresi
#model regresi
model<- lm(ipm~tahun, data = dtGorontalo)
summary(model)
```

Model yang dihasilkan adalah $$y_i=-1118+0.5873x_t$$ Berdasarkan ringkasan model dapat diketahui bahwa hasil uji F memiliki *p-value* \< $\alpha$ (5%). Artinya, minimal terdapat satu variabel yang berpengaruh nyata terhadap model. Hasil uji-t parsial kedua parameter regresi, yaitu intersep dan koefisien regresi juga menunjukkan hal yang sama, yaitu memiliki *p-value* \< $\alpha$ (5%) sehingga nyata dalam taraf 5%. Selanjutnya dapat dilihat juga nilai $R^2=0.9934$. Artinya, sebesar 99.34% keragaman nilai IPM dapat dijelaskan oleh peubah tahun. Hasil ini menunjukkan hasil yang bagus, seolah mendapatkan hasil terbaik. Namun, kita perlu melakukan uji terhadap sisaannya seperti berikut ini.

```{r}
#sisaan dan fitted value
sisaan<- residuals(model)
fitValue<- predict(model)

#Diagnostik dengan eksploratif
par(mfrow = c(2,2))
qqnorm(sisaan)
qqline(sisaan, col = "steelblue", lwd = 2)
plot(fitValue, sisaan, col = "steelblue", pch = 20, xlab = "Sisaan", ylab = "Fitted Values", main = "Sisaan vs Fitted Values")
abline(a = 0, b = 0, lwd = 2)
hist(sisaan, col = "steelblue")
plot(seq(1,12,1), sisaan, col = "steelblue", pch = 20, xlab = "Sisaan", ylab = "Order", main = "Sisaan vs Order")
lines(seq(1,12,1), sisaan, col = "red")
abline(a = 0, b = 0, lwd = 2)
```

Dua plot di samping kiri digunakan untuk melihat apakah sisaan menyebar normal. Normal Q-Q Plot di atas menunjukkan bahwa sisaan cenderung menyebar normal, tetapi histogram dari sisaan tidak menunjukkan demikian. Selanjutnya, dua plot di samping kanan digunakan untuk melihat autokorelasi. Plot Sisaan vs *Fitted Value* dan Plot Sisaan vs *Order* menunjukkan adanya pola pada sisaan. Untuk lebih lanjut akan digunakan uji formal melihat normalitas sisaan dan plot ACF dan PACF untuk melihat apakah ada autokorelasi atau tidak.

```{r}
#Melihat Sisaan Menyebar Normal/Tidak
#H0: sisaan mengikuti sebaran normal
#H1: sisaan tidak mengikuti sebaran normal
shapiro.test(sisaan)
ks.test(sisaan, "pnorm", mean=mean(sisaan), sd=sd(sisaan))
```

Berdasarkan uji formal Saphiro-Wilk dan Kolmogorov-Smirnov didapatkan nilai *p-value* \> $\alpha$ (5%). Artinya, cukup bukti untuk menyatakan sisaan berdistribusi normal.

```{r}
#ACF dan PACF identifikasi autokorelasi
par(mfrow = c(1,2))
acf(sisaan)
pacf(sisaan)
```

Berdasarkan plot ACF dan PACF, terlihat semua dalam rentang batas dan tidak ada yang signifikan. Namun, untuk lebih memastikan akan dilakukan uji formal dengan uji Durbin Watson.

```{r}
#Deteksi autokorelasi dengan uji-Durbin Watson
#H0: tidak ada autokorelasi
#H1: ada autokorelasi
dwtest(model)
```

Berdasarkan hasil DW Test, didapatkan nilai $DW = 1.2644$ dan *p-value* = $0.03741$. Berdasarkan tabel Durbin-Watson diperoleh nilai $DL = 0.9771$ dan $DU = 1.331$. Nilai DW masih berada di antara nilai DL dan DU. Artinya, berada di daerah inkonklusif, tidak dapat dikatakan berada di daerah autokorelasi positif maupun bebas dari autokorelasi. Namun, dengan nilai *p-value* \< 0.05 dapat disimpulkan bahwa tolak H0, cukup bukti mengatakan adanya autokorelasi. Oleh karena itu, diperlukan penangan autokorelasi. Penanganan yang akan digunakan menggunakan dua metode, yaitu Cochrane-Orcutt dan Hildret-Lu.

## Penanganan Autokorelasi

### Metode Cochrane-Orcutt

Penanganan metode Cochrane-Orcutt dapat dilakukan dengan bantuan packages Orcutt pada aplikasi `R` maupun secara manual. Berikut ini ditampilkan cara menggunakan bantuan `library` *packages* `Orcutt`.

```{r}
#Penanganan Autokorelasi Cochrane-Orcutt
modelCO<-cochrane.orcutt(model)
modelCO
```

Hasil keluaran model setelah dilakukan penanganan adalah sebagai berikut. $$y_i=-1062.042646+0.559755x_t$$ Hasil juga menunjukkan bahwa nilai DW dan p-value meningkat menjadi $1.49014$ dan $0.09403$. Nilai DW sudah berada pada rentang DU \< DW \< 4-DU atau $1.331 < DW < 2.669$. Hal tersebut juga didukung dengan nilai *p-value* \> 0.05, artinya belum cukup bukti menyatakan bahwa sisaan terdapat autokorelasi pada taraf nyata 5%. Untuk nilai $ρ ̂$ optimum yang digunakan adalah $0.3409214$. Nilai tersebut dapat diketahui dengan *syntax* berikut.

```{r}
#Rho optimum
rho<- modelCO$rho
rho
```

Selanjutnya akan dilakukan transformasi secara manual dengan syntax berikut ini.

```{r}
#Transformasi Manual
ipm.trans<- ipm[-1]-ipm[-12]*rho
tahun.trans<- tahun[-1]-tahun[-12]*rho
modelCOmanual<- lm(ipm.trans~tahun.trans)
summary(modelCOmanual)
```

Hasil model transformasi bukan merupakan model sesungguhnya. Koefisien regresi masih perlu dicari kembali mengikuti $β_0^*=β_0+ρ ̂β_0$ dan $β_1^*=β_1$.

```{r}
#Mencari Penduga Koefisien Regresi setelah Transformasi ke Persamaan Awal
b0bintang <- modelCOmanual$coefficients[-2]
b0 <- b0bintang/(1-rho)
b1 <- modelCOmanual$coefficients[-1]
b0
b1
```

Hasil perhitungan koefisien regresi tersebut akan menghasilkan hasil yang sama dengan model yang dihasilkan menggunakan *packages*.

### Metode Hildreth-Lu

Penanganan kedua adalah menggunakan metode Hildreth-Lu. Metode ini akan mencari nilai SSE terkecil dan dapat dicari secara manual maupun menggunakan packages. Jika menggunakan packages, gunakan `library` *packages* `HORM`.

```{r}
#Penanganan Autokorelasi Hildreth lu
# Hildreth-Lu
hildreth.lu.func<- function(r, model){
  x <- model.matrix(model)[,-1]
  y <- model.response(model.frame(model))
  n <- length(y)
  t <- 2:n
  y <- y[t]-r*y[t-1]
  x <- x[t]-r*x[t-1]
  
  return(lm(y~x))
}

#Pencariab rho yang meminimumkan SSE
r <- c(seq(0.1,0.9, by= 0.1))
tab <- data.frame("rho" = r, "SSE" = sapply(r, function(i){deviance(hildreth.lu.func(i, model))}))
round(tab, 4)
```

Pertama-tama akan dicari di mana kira-kira $ρ$ yang menghasilkan SSE minimum. Pada hasil di atas terlihat $ρ$ minimum ketika 0.3. Namun, hasil tersebut masih kurang teliti sehingga akan dicari kembali $ρ$ yang lebih optimum dengan ketelitian yang lebih. Jika sebelumnya jarak antar $ρ$ yang dicari adalah 0.1, kali ini jarak antar $ρ$ adalah 0.001 dan dilakukan pada selang 0.2 sampai dengan 0.5.

```{r}
#Rho optimal di sekitar 0.4
rOpt <- seq(0.2,0.5, by= 0.001)
tabOpt <- data.frame("rho" = rOpt, "SSE" = sapply(rOpt, function(i){deviance(hildreth.lu.func(i, model))}))
head(tabOpt[order(tabOpt$SSE),])

#Grafik SSE optimum
par(mfrow = c(1,1))
plot(tab$SSE ~ tab$rho , type = "l", xlab = "Rho", ylab = "SSE")
abline(v = tabOpt[tabOpt$SSE==min(tabOpt$SSE),"rho"], lty = 2, col="red",lwd=2)
text(x=0.341, y=0.2397500, labels = "rho=0.341", cex = 0.8)
```

Perhitungan yang dilakukan aplikasi `R` menunjukkan bahwa nilai $ρ$ optimum, yaitu saat SSE terkecil terdapat pada nilai $ρ=0.341$. Hal tersebut juga ditunjukkan pada plot. Selanjutnya, model dapat didapatkan dengan mengevaluasi nilai $ρ$ ke dalam fungsi `hildreth.lu.func`, serta dilanjutkan dengan pengujian autokorelasi dengan uji Durbin-Watson. Namun, setelah pengecekan tersebut tidak lupa koefisien regresi tersebut digunakan untuk transformasi balik. Persamaan hasil transformasi itulah yang menjadi persamaan sesungguhnya.

```{r}
#Model terbaik
modelHL <- hildreth.lu.func(0.341, model)
summary(modelHL)

#Transformasi Balik
cat("y = ", coef(modelHL)[1]/(1-0.341), "+", coef(modelHL)[2],"x", sep = "")
```

Setelah dilakukan tranformasi balik, didapatkan model dengan metode Hildreth-Lu sebagai berikut. $$y_i=-1062.032+0.5597492x_t$$

```{r}
#Deteksi autokorelasi
dwtest(modelHL)
```

Hasil uji Durbin-Watson juga menunjukkan bawah nilai DW sebesar $1.4092$ berada pada selang daerah tidak ada autokorelasi, yaitu pada rentang DU \< DW \< 4-DU atau $1.331 < DW < 2.669$. Hal tersebut juga didukung oleh *p-value* sebesar $0.09404$, di mana *p-value* \> $\alpha$=5%. Artinya tak tolak $H_0$ atau belum cukup bukti menyatakan bahwa ada autokorelasi dalam data nilai IPM dengan metode Hildreth-Lu pada taraf nyata 5%.

Terakhir, akan dibandingkan nilai SSE dari ketiga metode (metode awal, metode Cochrane-Orcutt, dan Hildreth-Lu).

```{r}
#Perbandingan
sseModelawal <- anova(model)$`Sum Sq`[-1]
sseModelCO <- anova(modelCOmanual)$`Sum Sq`[-1]
sseModelHL <- anova(modelHL)$`Sum Sq`[-1]
mseModelawal <- sseModelawal/length(ipm)
mseModelCO <- sseModelCO/length(ipm)
mseModelHL <- sseModelHL/length(ipm)
akurasi <- matrix(c(sseModelawal,sseModelCO,sseModelHL,
                    mseModelawal,mseModelCO,mseModelHL),nrow=2,ncol=3,byrow = T)
colnames(akurasi) <- c("Model Awal", "Model Cochrane-Orcutt", "Model Hildreth-Lu")
row.names(akurasi) <- c("SSE","MSE")
akurasi
```

Berdasarkan hasil tersebut dapat diketahui bahwa hasil penanganan autokorelasi dengan metode Cochrane-Orcutt dan Hildreth-Lu memiliki SSE yang sama, sebesar $0.23975$ dan lebih baik dibandingkan model awal ketika autokorelasi masih terjadi, yaitu sebesar $0.3286364$.

# Simpulan

Autokorelasi yang terdapat pada data IPM terjadi akibat adanya korelasi di antara unsur penyusunnya. Indikator IPM yang erat hubungannya dengan perekonomian sangat rawan menjadi penyebab adanya autokorelasi. Adanya autokorelasi menyebabkan model regresi kurang baik karena akan meingkatkan galatnya. Autokorelasi dapat dideteksi secara eksploratif melalui plot sisaan, ACF, dan PACF, serta dengan uji formal Durbin-Watson. Namun, autokorelasi tersebut dapat ditangani dengan metode Cochrane-Orcutt dan Hildreth-Lu. Kedua metode menghasilkan nilai SSE yang sama, artinya keduanya baik untuk digunakan.

# Daftar Pustaka

Aprianto A, Debataraja NN, Imro'ah N. 2020. Metode cochrane-orcutt untuk mengatasi autokorelasi pada estimasi parameter ordinary least squares. *Bimaster : Buletin Ilmiah Matematika, Statistika dan Terapannya*. 9(1):95--102. <doi:10.26418/bbimst.v9i1.38590>.

BPS. 2021a. *Indeks Pembangunan Manusia 2020*. Jakarta (ID): Badan Pusat Statistik.

BPS. 2021b. Indeks Pembangunan Manusia (IPM) 2021. *Berita Resmi Statistik*., siap terbit.

---
title: "Pertemuan 3 - Regresi dengan Peubah Lag"
author:
- Adelia Putri Pangestika
- Muhammad Rizky Nurhambali
output:
  html_document:
    theme: yeti
    toc: true
    toc_float: true
  word_document: default
  pdf_document: default
---

## *Packages*

```{r, echo=FALSE}
#PACKAGES
#install.packages("dLagM") #install jika belum ada
#install.packages("dynlm") #install jika belum ada
#install.packages("MLmetrics") #install jika belum ada
library(dLagM)
library(dynlm)
library(MLmetrics)
library(lmtest)
library(car)
```

## Impor Data

```{r}
data <- rio::import("https://raw.githubusercontent.com/rizkynurhambali/Praktikum-MPDW-2324/main/Pertemuan%203/Data%20Asli.csv")
str(data)
data
```

## Pembagian Data

```{r}
#SPLIT DATA
train<-data[1:15,]
test<-data[16:20,]
```

```{r}
#data time series
train.ts<-ts(train)
test.ts<-ts(test)
data.ts<-ts(data)
```

## Model Koyck

Model Koyck didasarkan pada asumsi bahwa semakin jauh jarak lag peubah independen dari periode sekarang maka semakin kecil pengaruh peubah lag terhadap peubah dependen.

Koyck mengusulkan suatu metode untuk menduga model dinamis distributed lag dengan mengasumsikan bahwa semua koefisien $\beta$ mempunyai tanda sama.

Model kyock merupakan jenis paling umum dari model infinite distributed lag dan juga dikenal sebagai geometric lag

$$
y_t=a(1-\lambda)+\beta_0X_t+\beta_1Z_t+\lambda Y_{t-1}+V_t
$$

dengan $$V_t=u_t-\lambda u_{t-1}$$

### Pemodelan

Pemodelan model Koyck dengan `R` dapat menggunakan `dLagM::koyckDlm()` . Fungsi umum dari `koyckDlm` adalah sebagai berikut.

```{r, eval=FALSE, message = FALSE, warning=FALSE, error=FALSE}
koyckDlm(x , y , intercept)
```

Fungsi `koyckDlm()` akan menerapkan model lag terdistribusi dengan transformasi Koyck satu prediktor. Nilai `x` dan `y` tidak perlu sebagai objek *time series* (`ts`). `intercept` dapat dibuat `TRUE` untuk memasukkan intersep ke dalam model.

```{r}
#MODEL KOYCK
model.koyck <- koyckDlm(x = train$Xt, y = train$Yt)
summary(model.koyck)
AIC(model.koyck)
BIC(model.koyck)
```

Dari hasil tersebut, didapat bahwa peubah $x_t$ dan $y_{t-1}$ memiliki nilai $P-Value<0.05$. Hal ini menunjukkan bahwa peubah $x_t$ dan $y_{t-1}$ berpengaruh signifikan terhadap $y$. Adapun model keseluruhannya adalah sebagai berikut

$$
\hat{Y_t}=-3.7335+1.1510X_t+0.4214Y_{t-1}
$$

### Peramalan dan Akurasi

Berikut adalah hasil peramalan y untuk 5 periode kedepan menggunakan model koyck

```{r}
fore.koyck <- forecast(model = model.koyck, x=test$Xt, h=5)
fore.koyck
mape.koyck <- MAPE(fore.koyck$forecasts, test$Yt)
#akurasi data training
GoF(model.koyck)
```

## Regression with Distributed Lag

Pemodelan model Regression with Distributed Lag dengan `R` dapat menggunakan `dLagM::dlm()` . Fungsi umum dari `dlm` adalah sebagai berikut.

```{r, eval=FALSE, error=FALSE}
dlm(formula , data , x , y , q , remove )
```

Fungsi `dlm()` akan menerapkan model lag terdistribusi dengan satu atau lebih prediktor. Nilai `x` dan `y` tidak perlu sebagai objek *time series* (`ts`). $q$ adalah integer yang mewakili panjang *lag* yang terbatas.

### Pemodelan (Lag=2)

```{r}
model.dlm <- dlm(x = train$Xt,y = train$Yt , q = 2)
summary(model.dlm)
AIC(model.dlm)
BIC(model.dlm)
```

Dari hasil diatas, didapat bahwa $P-value$ dari intercept dan $x_{t-1}<0.05$. Hal ini menunjukkan bahwa intercept dan $x_{t-1}$ berpengaruh signifikan terhadap $y$. Adapun model keseluruhan yang terbentuk adalah sebagai berikut

$$
\hat{Y_t}=-9.6779+0.3179X_t+1.5276X_{t-1}+0.2651X_{t-2}
$$

### Peramalan dan Akurasi

Berikut merupakan hasil peramalan $y$ untuk 5 periode kedepan

```{r}
fore.dlm <- forecast(model = model.dlm, x=test$Xt, h=5)
fore.dlm
mape.dlm <- MAPE(fore.dlm$forecasts, test$Yt)
#akurasi data training
GoF(model.dlm)
```

### *Lag* Optimum

```{r}
#penentuan lag optimum 
finiteDLMauto(formula = Yt ~ Xt,
              data = data.frame(train), q.min = 1, q.max = 6,
              model.type = "dlm", error.type = "AIC", trace = FALSE)
```

Berdasarkan output tersebut, lag optimum didapatkan ketika lag=6. Selanjutnya dilakukan pemodelan untuk lag=6

```{r}
#model dlm dengan lag optimum
model.dlm2 <- dlm(x = train$Xt,y = train$Yt , q = 6)
summary(model.dlm2)
AIC(model.dlm2)
BIC(model.dlm2)
```

Dari hasil tersebut terdapat beberapa peubah yang berpengaruh signifikan terhadap taraf nyata 5% yaitu $x_t$ , $x_{t-2}$ , $x_{t-4}$ , $x_{t-6}$. Adapun keseluruhan model yang terbentuk adalah

$$
\hat{Y_t}=21.42223+1.68749X_t+...-3.47612X_{t-6}
$$

Adapun hasil peramalan 5 periode kedepan menggunakan model tersebut adalah sebagai berikut

```{r}
#peramalan dan akurasi
fore.dlm2 <- forecast(model = model.dlm2, x=test$Xt, h=5)
mape.dlm2<- MAPE(fore.dlm2$forecasts, test$Yt)
#akurasi data training
GoF(model.dlm2)
```

Model tersebut merupakan model yang sangat baik dengan nilai MAPE yang kurang dari 10%.

## Model Autoregressive

Peubah dependen dipengaruhi oleh peubah independen pada waktu sekarang, serta dipengaruhi juga oleh peubah dependen itu sendiri pada satu waktu yang lalu maka model tersebut disebut *autoregressive* (Gujarati 2004).

### Pemodelan

Pemodelan Autoregressive dilakukan menggunakan fungsi `dLagM::ardlDlm()` . Fungsi tersebut akan menerapkan *autoregressive* berordo $(p,q)$ dengan satu prediktor. Fungsi umum dari `ardlDlm()` adalah sebagai berikut.

```{r, eval=FALSE}
ardlDlm(formula = NULL , data = NULL , x = NULL , y = NULL , p = 1 , q = 1 , 
         remove = NULL )
```

Dengan $p$ adalah integer yang mewakili panjang *lag* yang terbatas dan $q$ adalah integer yang merepresentasikan ordo dari proses *autoregressive*.

```{r}
model.ardl <- ardlDlm(x = train$Xt, y = train$Yt, p = 1 , q = 1)
summary(model.ardl)
AIC(model.ardl)
BIC(model.ardl)
```

Hasil di atas menunjukkan bahwa selain peubah $x_{t-1}$, hasil uji t menunjukkan nilai-p pada peubah $\ge0.05$ Hal ini menunjukkan bahwa peubah $x_{t-1}$ berpengaruh signifikan terhadap $y_t$, sementara $x_t$ dan $y_{t-1}$ berpengaruh signifikan terhadap $y_t$. Model keseluruhannya adalah sebagai berikut:

$$
\hat{Y}=-8,3594+0,3563X_t+1,4557X_{t-1}+0,1408Y_{t-1}
$$

### Peramalan dan Akurasi

```{r}
fore.ardl <- forecast(model = model.ardl, x=test$Xt, h=5)
fore.ardl
```

Data di atas merupakan hasil peramalan untuk 5 periode ke depan menggunakan Model Autoregressive dengan $p=1$ dan $q=1$.

```{r}
mape.ardl <- MAPE(fore.ardl$forecasts, test$Yt)
mape.ardl
#akurasi data training
GoF(model.ardl)
```

Berdasarkan akurasi di atas, terlihat bahwa nilai MAPE keduanya tidak jauh berbeda. Artinya, model regresi dengan distribusi lag ini tidak `overfitted` atau `underfitted`

### *Lag* Optimum

```{r}
#penentuan lag optimum
model.ardl.opt <- ardlBoundOrders(data = data.frame(data), ic = "AIC", 
                                  formula = Yt ~ Xt )
min_p=c()
for(i in 1:6){
  min_p[i]=min(model.ardl.opt$Stat.table[[i]])
}
q_opt=which(min_p==min(min_p, na.rm = TRUE))
p_opt=which(model.ardl.opt$Stat.table[[q_opt]] == 
              min(model.ardl.opt$Stat.table[[q_opt]], na.rm = TRUE))
data.frame("q_optimum" = q_opt, "p_optimum" = p_opt, 
           "AIC"=model.ardl.opt$min.Stat)
```

Dari tabel di atas, dapat terlihat bahwa nilai AIC terendah didapat ketika $p=6$ dan $q=1$, yaitu sebesar `-20,56587`. Artinya, model autoregressive optimum didapat ketika $p=6$ dan $q=1$.

Selanjutnya dapat dilakukan pemodelan dengan nilai $p$ dan $q$ optimum seperti inisialisasi di langkah sebelumnya.

## Pemodelan DLM & ARDL dengan Library `dynlm`

Pemodelan regresi dengan peubah *lag* tidak hanya dapat dilakukan dengan fungsi pada *packages* `dLagM` , tetapi terdapat *packages* `dynlm` yang dapat digunakan. Fungsi `dynlm` secara umum adalah sebagai berikut.

```{r, eval=FALSE}
dynlm(formula, data, subset, weights, na.action, method = "qr",
  model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE,
  contrasts = NULL, offset, start = NULL, end = NULL, ...)
```

Untuk menentukan `formula` model yang akan digunakan, tersedia fungsi tambahan yang memungkinkan spesifikasi dinamika (melalui `d()` dan `L()`) atau pola linier/siklus dengan mudah (melalui `trend()`, `season()`, dan `harmon()`). Semua fungsi formula baru mengharuskan argumennya berupa objek deret waktu (yaitu, `"ts"` atau `"zoo"`).

```{r}
#sama dengan model dlm q=1
cons_lm1 <- dynlm(Yt ~ Xt+L(Xt),data = train.ts)
#sama dengan model ardl p=1 q=0
cons_lm2 <- dynlm(Yt ~ Xt+L(Yt),data = train.ts)
#sama dengan ardl p=1 q=1
cons_lm3 <- dynlm(Yt ~ Xt+L(Xt)+L(Yt),data = train.ts)
#sama dengan dlm p=2
cons_lm4 <- dynlm(Yt ~ Xt+L(Xt)+L(Xt,2),data = train.ts)
```

### Ringkasan Model

```{r}
summary(cons_lm1)
summary(cons_lm2)
summary(cons_lm3)
summary(cons_lm4)
```

### SSE

```{r}
deviance(cons_lm1)
deviance(cons_lm2)
deviance(cons_lm3)
deviance(cons_lm4)
```

### Uji Diagnostik

```{r}
#uji model
if(require("lmtest")) encomptest(cons_lm1, cons_lm2)
```

#### Autokorelasi

```{r}
#durbin watson
dwtest(cons_lm1)
dwtest(cons_lm2)
dwtest(cons_lm3)
dwtest(cons_lm4)
```

#### Heterogenitas

```{r}
bptest(cons_lm1)
bptest(cons_lm2)
bptest(cons_lm3)
bptest(cons_lm4)
```

#### Kenormalan

```{r}
shapiro.test(residuals(cons_lm1))
shapiro.test(residuals(cons_lm2))
shapiro.test(residuals(cons_lm3))
shapiro.test(residuals(cons_lm4))
```

## Perbandingan Model

```{r}
akurasi <- matrix(c(mape.koyck, mape.dlm, mape.dlm2, mape.ardl))
row.names(akurasi)<- c("Koyck","DLM 1","DLM 2","Autoregressive")
colnames(akurasi) <- c("MAPE")
akurasi
```

Berdasarkan nilai MAPE, model paling optimum didapat pada Model Koyck karena memiliki nilai MAPE yang terkecil.

### Plot

```{r}
par(mfrow=c(1,1))
plot(test$Xt, test$Yt, type="b", col="black", ylim=c(120,250))
points(test$Xt, fore.koyck$forecasts,col="red")
lines(test$Xt, fore.koyck$forecasts,col="red")
points(test$Xt, fore.dlm$forecasts,col="blue")
lines(test$Xt, fore.dlm$forecasts,col="blue")
points(test$Xt, fore.dlm2$forecasts,col="orange")
lines(test$Xt, fore.dlm2$forecasts,col="orange")
points(test$Xt, fore.ardl$forecasts,col="green")
lines(test$Xt, fore.ardl$forecasts,col="green")
legend("topleft",c("aktual", "koyck","DLM 1","DLM 2", "autoregressive"), lty=1, col=c("black","red","blue","orange","green"), cex=0.8)
```

Berdasarkan plot tersebut, terlihat bahwa plot yang paling mendekati data aktualnya adalah Model koyck, sehingga dapat disimpulkan model terbaik dalam hal ini adalah model regresi koyck

## Pengayaan (Regresi Berganda)

### Data

```{r}
data(M1Germany)
data1 = M1Germany[1:144,]
```

### DLM

```{r}
#Run the search over finite DLMs according to AIC values
finiteDLMauto(formula = logprice ~ interest+logm1,
              data = data.frame(data1), q.min = 1, q.max = 5,
              model.type = "dlm", error.type = "AIC", trace = FALSE)
```

```{r}
#model dlm berganda
model.dlmberganda = dlm(formula = logprice ~ interest + logm1,
                data = data.frame(data1) , q = 5)
summary(model.dlmberganda)

model.dlmberganda2 = dlm(formula = logprice ~ interest + logm1,
                        data = data.frame(data1) , q = 1)
summary(model.dlmberganda2)
```

### ARDL

```{r}
#Mencari orde lag optimum model ARDL
ardlBoundOrders(data = data1 , formula = logprice ~ interest + logm1,
                ic="AIC")

model.ardlDlmberganda = ardlDlm(formula = logprice ~ interest + logm1,
                        data = data.frame(data1) , p = 4 , q = 4)
summary(model.ardlDlmberganda)
```

```{r}
#model p interest 0 p logm1 4 
rem.p = list(interest = c(1,2,3,4))
remove = list(p = rem.p)
model.ardlDlmberganda2 = ardlDlm(formula = logprice ~ interest + logm1,
                        data = data.frame(data1) , p = 4 , q = 4 ,
                        remove = remove)
summary(model.ardlDlmberganda2)
```

Proses selanjutnya sama dengan pemodelan menggunakan peubah tunggal.


PERT 4 
---
title: "AR-MA manual"
output:
  pdf_document: default
  html_document: default
date: "2023-09-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## White Noise

Pembangkitan data berpola AR, MA, ARMA, dan banyak proses deret waktu lainnya diawali pembangkitan *white noise*. *White noise* merupakan sederet nilai dari peubah bebas stokastik identik. Oleh karena itu, *white noise* memiliki dua karakteristik penting:

1.  *White noise* tidak memiliki autokorelasi (**karena saling bebas**)
2.  Nilai harapan dan ragam *white noise* sama (**karena berasal dari peubah acak bebas stokastik identik**)

*White noise* dibangkitkan dari suatu peubah acak, umumnya peubah acak normal.

```{r}
wn <- rnorm(200)
ts.plot(wn)
```

Dapat terlihat bahwa *white noise* tidak memiliki autokorelasi dari ACF. Perhatikan bahwa lag ke-0 adalah korelasi observasi ke-t dengan dirinya sendiri. Nilai korelasi tersebut pasti 1. Sebagai alternatif, lag pertama di plot ACF dapat ditetapkan sebagai 1 (alih-alih 0) dengan menambahkan argumen `xlim(1, lag akhir)`. Plot tersebut dapat disandingkan bersamaan dengan membuat matriks $1 \times 2$ dengan `par(mfrow = c(1,2))`.

```{r}
par(mfrow = c(1, 2)) 
acf(wn)
acf(wn, xlim = c(1, 20))
```

## Proses MA

Proses MA dapat dituliskan sebagai berikut:

$$
y_{t} = c + e_t + \theta_{1}e_{t-1} + \theta_{2}e_{t-2} + \dots + \theta_{q}e_{t-q} = c+{e_t+\sum_{i=1}^p \theta_ie_{t-i}}
$$ Terlihat bahwa $e_t$, atau *white noise*, berperan penting dalam pembangkitan proses MA.

## Pembangkitan Proses MA(1)

Akan dicoba membangkitkan proses MA paling sederhana, yaitu MA(1) dengan $\theta = 0.5$ sebanyak 200 observasi dan $c=0$. Karena diperlukan satu nilai awal untuk $e_{t-1}$, masukkan nilai pertama white noise sebagai nilai awal tersebut.

```{r}
set.seed(1234)
ma <- wn[1]
```

Nilai-nilai selanjutnya dapat dicari melalui *loop*. Bentuk loop dapat dilihat dari rumus MA(1) yang hendak dibangkitkan:

$$
y_t = e_t+0.5e_{t-1}
$$

```{r}
for(i in 2:200){
   ma[i] <- wn[i] + 0.5 * wn[i - 1] 
}
ma
```

Selain menggunakan cara di atas, pembangkitan proses MA(1) dapat dilakukan dengan fungsi `arima.sim()` sebagai berikut.

```{r}
ma1 <- arima.sim(list(order=c(0,0,1), ma=0.5), n=200)
ma1
```

## Karakteristik MA(1)

### Plot Time Series

```{r}
ts.plot(ma)
```

Berdasarkan plot time series, terlihat bahwa data MA(1) yang dibangkitkan stasioner dalam rataan

### Plot ACF

```{r}
acf(ma,lag.max = 20)
```

Berdasarkan plot AFC tersebut, terlihat bahwa plot ACF *cuts off* di lag pertama

### Plot PACF

```{r}
pacf(ma)
```

Berdasarkan plot PACF tersebut, terlihat bahwa plot PACF cenderung *tails off* dan membentuk gelombang sinus

### Plot EACF

```{r}
TSA::eacf(ma)
```

Berdasarkan pola segitiga nol pada plot EACF, terlihat bahwa segitiga nol berada pada ordo AR(0) dan ordo MA(1)

### Scatterplot Antar Lag

#### Korelasi antara $Y_t$ dengan $Y_{t-1}$

```{r}
#Yt
yt_ma <- ma[-1]
yt_ma
#Yt-1
yt_1_ma <- ma[-200]
yt_1_ma
```

```{r}
plot(y=yt_ma,x=yt_1_ma)
```

Berdasarkan scatterplot tersebut, terlihat bahwa terdapat hubungan positif antara $Y_t$ dengan $Y_{t-1}$. Hal ini sesuai dengan teori yang ada

```{r}
cor(yt_ma,yt_1_ma)
```

Korelasi antara $Y_t$ dengan $Y_{t-1}$ dari hasil simulasi mendekati perhitungan teoritis yaitu

$$
\rho_1=\frac{-\theta}{1+(-\theta)^2}=\frac{-(-0.5)}{1+(-0.5)^2}=0.4
$$

#### Korelasi antara $Y_t$ dengan $Y_{t-2}$

```{r}
#Yt
yt_ma2 <- ma[-c(1,2)]
yt_ma2
#Yt-2
yt_2_ma <- ma[-c(199,200)]
yt_2_ma
```

```{r}
plot(y=yt_ma2,x=yt_2_ma)
```

Berdasarkan scatterplot tersebut, terlihat bahwa cenderung tidak terdapat hubungan antara $Y_t$ dengan $Y_{t-2}$.

```{r}
cor(yt_ma2,yt_2_ma)
```

Korelasi antara $Y_t$ dengan $Y_{t-2}$ hasil simulasi mendekati teori yang ada yaitu 0.

## Proses AR

Proses AR dapat dituliskan sebagai berikut:

$$ y_{t} = c + e_t + \phi_{1}Y_{t-1} + \phi_{2}Y_{t-2} + \dots + \phi_{q}Y_{t-q} = c+{e_t+\sum_{i=1}^p \phi_iY_{t-i}} $$ Terlihat bahwa $Y_t$ berperan penting dalam pembangkitan proses AR.

## Pembangkitan Proses AR

Akan dicoba membangkitkan proses AR paling sederhana, yaitu AR(1) dengan $\phi = 0.7$ sebanyak 200 observasi dan $c=0$.

```{r}
set.seed(1234)
```

Nilai-nilai selanjutnya dapat dicari melalui *loop*. Bentuk loop dapat dilihat dari rumus AR(1) yang hendak dibangkitkan:

$$ Y_t = e_t+0.7Y_{t-1} $$

```{r}
n<-length(wn)
n
ar <- c(1:n) 
for (i in 2:n) {ar[i]<-wn[i]+0.7*ar[i-1]}
ar
```

Selain menggunakan cara di atas, pembangkitan proses AR dapat dilakukan dengan fungsi `arima.sim()` sebagai berikut.

```{r}
ar1 <- arima.sim(list(order=c(1,0,0), ar=0.7), n=200)
ar1
```

## Karakteristik AR(1)

### Plot Time Series

```{r}
ts.plot(ar)
```

Berdasarkan plot time series tersebut terlihat bahwa data cenderung stasioner pada rataan

### Plot ACF

```{r}
acf(ar)
```

Berdasarkan plot ACF tersebut terlihat bahwa plot ACF cenderung *tails off* dan cenderung membentuk pola grafik sinus

### Plot PACF

```{r}
pacf(ar)
```

Berdasarkan plot PACF tersebut, terlihat bahwa plot PACF *cuts off* pada lag pertama, sejalan dengan teori yang ada

### Plot EACF

```{r}
TSA::eacf(ar)
```

Berdasarkan pola segitiga nol pada plot EACF, terlihat bahwa segitiga nol berada pada ordo AR(1) dan ordo MA(0)

### Scatterplot Antar Lag

#### Korelasi antara $Y_t$ dengan $Y_{t-1}$

```{r}
#Yt
yt_ar <- ar[-1]
yt_ar
#Yt-1
yt_1_ar <- ar[-200]
yt_1_ar
```

```{r}
plot(y=yt_ar,x=yt_1_ar)
```

Berdasarkan scatterplot tersebut, terlihat bahwa terdapat hubungan positif antara $Y_t$ dengan $Y_{t-1}$. Hal ini sesuai dengan teori yang ada

```{r}
cor(yt_ar,yt_1_ar)
```

Korelasi antara $Y_t$ dengan $Y_{t-1}$ dari hasil simulasi mendekati perhitungan teoritis yaitu $\rho_1=\phi^1=0.7$

#### Korelasi antara $Y_t$ dengan $Y_{t-2}$

```{r}
#Yt
yt_ar2 <- ar[-c(1,2)]
yt_ar2
#Yt-2
yt_2_ar <- ar[-c(199,200)]
yt_2_ar
```

```{r}
plot(y=yt_ar2,x=yt_2_ar)
```

Berdasarkan scatterplot tersebut, terlihat bahwa terdapat hubungan positif antara $Y_t$ dengan $Y_{t-2}$. Hal ini sesuai dengan teori yang ada

```{r}
cor(yt_ar2,yt_2_ar)
```

Korelasi antara $Y_t$ dengan $Y_{t-2}$ dari hasil simulasi mendekati perhitungan teoritis yaitu $\rho_2=\phi^2=0.49$.

## Fungsi pembangkitan ARMA

Setelah mengetahui cara membangkitkan data berpola AR, MA, dan ARMA sederhana, bagaimana cara melakukan pembangkitan data berpola tersebut yang lebih kompleks? Apakah dapat dibuat suatu fungsi yang fleksibel yang memungkinan pembangkitan dengan berapapun jumlah koefisien?

Pertama, lihat kembali bentuk umum data berpola ARMA.

$$
y_{t} = c + \sum_{i=1}^p \phi_{i}y_{t-i} + \sum_{j=1}^q e_{t-j}+ e_{t}
$$

Komponen $c$ dan $e_{t}$ cukup mudah untuk dibuat dan dicari. Bagaimana untuk komponen AR dan MA? Bayangkan ada koefisien dan data sebagai berikut:

$$
\begin{aligned}
\begin{bmatrix}
\phi_1 \  \phi_2 \ \phi_3
\end{bmatrix}&=
\begin{bmatrix}
0.3 \ 0.5 \ 0.2
\end{bmatrix}
\\
\begin{bmatrix}
y_{t-1} \  y_{t-2} \ y_{t-3}
\end{bmatrix}&=
\begin{bmatrix}
1 \ 2 \ 3
\end{bmatrix}
\end{aligned}
$$

Maka dari itu,

$$
\begin{aligned}
\begin{bmatrix}
\phi_1 \  \phi_2 \ \phi_3
\end{bmatrix}
\begin{bmatrix}
y_{t-1} \\  y_{t-2} \\ y_{t-3}
\end{bmatrix} &= \phi_1 \ y_{t-1}+\phi_2 \ y_{t-2}+\phi_3 \ y_{t-3}
\\
\begin{bmatrix}
 0.3 \ 0.5 \ 0.2
\end{bmatrix}
\begin{bmatrix}
1 \\ 2 \\ 3
\end{bmatrix} & = 0.3 \cdot1+0.5 \cdot 2+0.2 \cdot 3\\
&=0.3+1+0.6 = 1.9
\end{aligned}
$$

Jika koefisien dan *white noise*/nilai deret waktu sebelumnya dapat diekstrak dalam bentuk vektor, dapat dilakukan perkalian matriks untuk mencari nilai bagian AR dan MA:

```{r}
set.seed(30)
coefs <- c(0.3, 0.5, 0.2)
e <- c(1, 2, 3)

coefs %*% e
```

Atau, dapat dilakukan perkalian *elementwise* yang dijumlahkan:

```{r}
coefs * e
sum(coefs * e)
```

Dari prinsip ini, dapat dibuat fungsi umum untuk membangkitkan data ARMA. Input dari fungsi adalah jumlah data yang hendak dibangkitkan, koefisien MA, dan koefisien AR

```{r}
arma.sim <- function(n, macoef, arcoef){
  manum <- length(macoef)
  arnum <- length(arcoef)
  stopifnot(manum < n & arnum < n)
  
  wn <- rnorm(n, sd = 0.5)
  init <- max(manum, arnum)

  arma <- wn[1:init]
  for(i in {init+1}:n){
   mastart <- i - manum
   maend <- i-1
   arstart <- i - arnum
   arend <- i-1
   arma[i] <- sum(arcoef * arma[arstart:arend]) + sum(macoef * wn[mastart:maend])  + wn[i]
   }
  return(arma)
}
```

Terlihat bahwa komponen $\sum_{i=1}^q y_{t-1}$ disimulasikan melalui `sum(arcoef * arma[arstart:arend])`. Jadi, koefisien dikalikan dengan data $y$ dari $t-q$ di mana q adalah jumlah koefisien AR, sampai data $t-1$. Lalu komponen $\sum_{j=1}^q e_{t-j}$ disimulasikan melalui `sum(macoef * wn[mastart:maend])`. Koefisien dikalikan dengan *white noise* $e$ dari $t-p$, p jumlah koefisien MA, sampai $t-1$.

```{r}
# beberapa contoh pembangkitan melalui fungsi

ma3 <- arma.sim(1000, c(0.4, 0.6,0.4), 0)
ar2 <- arma.sim(1000, 0, c(0.3, 0.6))

par(mfrow = c(2, 2))
acf(ma3)
pacf(ma3)
acf(ar2)
pacf(ar2)
```

```{r}
#contoh untuk ARMA
arma22 <- arma.sim(2000, c(0.3, 0.4), c(0.3,0.4))

arma22 |> arima(c(2,0,2))
```

```{r}
set.seed(1234)
n = length(wn)
phi1 = 0.7
theta1 = 0.5

y.arma=c(1:n)
for (i in 2:n){y.arma[i] = phi1*y.arma[i-1] + theta1*wn[i-1]+wn[i]}
y.arma
```

Pembangkitan ARMA(p,q) juga dapat dilakukan dengan fungsi `arima.sim` sebagai berikut.

```{r}
arma11 <- arima.sim(list(order=c(1,0,1), ar = 0.7, ma = 0.5), n=200)
arma11
```

## Karakteristik ARMA(1,1)

### Plot Time Series

```{r}
par(mfrow = c(1, 2))
ts.plot(y.arma)
ts.plot(arma11)
par(mfrow = c(1, 1))
```

Berdasarkan plot time series tersebut, terlihat bahwa model ARMA(1,1) cenderung stasioner dalam rataan

### Plot ACF

```{r}
par(mfrow = c(1, 2))
acf(y.arma)
acf(arma11)
par(mfrow = c(1, 1))
```

Berdasarkan plot ACF tersebut, terlihat bahwa model ARMA(1,1) hasil simulasi memiliki plot ACF yang *tails off*, sesuai dengan teori yang ada

### Plot PACF

```{r}
par(mfrow = c(1, 2))
pacf(y.arma)
pacf(arma11)
par(mfrow = c(1, 1))
```

Berdasarkan plot PACF tersebut, terlihat bahwa model ARMA(1,1) hasil simulasi memiliki plot PACF yang *tails off*, sesuai dengan teori

### Plot EACF

```{r}
TSA::eacf(y.arma)
TSA::eacf(arma11)
```

Berdasarkan pola segitiga nol pada plot EACF, terlihat bahwa segitiga nol berada pada ordo AR(1) dan ordo MA(1)

### Scatterplot Antar Lag

#### Korelasi antara $Y_t$ dengan $Y_{t-1}$

```{r}
#Yt
yt_arma <- arma11[-1]
yt_arma
#Yt-1
yt_1_arma <- arma11[-200]
yt_1_arma
```

```{r}
plot(y=yt_arma,x=yt_1_arma)
```

Berdasarkan scatterplot tersebut, terlihat bahwa terdapat hubungan positif antara $Y_t$ dengan $Y_{t-1}$. Hal ini sesuai dengan teori yang ada

```{r}
cor(yt_arma,yt_1_arma)
```

Korelasi antara $Y_t$ dengan $Y_{t-1}$ dari hasil simulasi mendekati perhitungan teoritis. $$
\rho_k = \frac{(1-\theta \phi)(\phi-\theta)}{1-2\theta\phi+\theta^2}\phi^{k-1} \:untuk \:k\ge1
$$

$$
\rho_1 = \frac{(1-((-0.5)(0.7)))(0.7-(-0.5))}{1-2(-0.5)(0.7)+(-0.5)^2}0.7^{1-1}=0,8307692 $$

PERT 5
---
title: "Data Tidak Stasioner"
output:
  html_document: default
  pdf_document: default
date: "2023-09-23"
---

```{r}
library(ggplot2)
library(tsibble)
library(tseries)
library(MASS)
```

```{r}
set.seed(8990)
```

## Stasioner dalam Rataan dan Ragam

Pada dasarnya, pembangkitan data ARIMA akan menghasilkan data yang stasioner dalam rataan dan ragam karena akan mengikuti fungsi *default*-nya yang mengikuti pembangkitan bilangan acak normal dengan `mean=0` dan `ragam=1` .

```{r}
stas <- arima.sim(n=200, list(order=c(1,0,1),ar= .2, ma=.2),mean=12)
```

### Plot *Time Series*

```{r}
plot_stas <- stas |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
plot_stas
mean(stas)
```

Plot deret waktu di atas menunjukkan bahwa data stasioner dalam rataan, ditandai dengan data yang menyebar di sekitar nilai tengahnya (18) dan stasioner dalam ragam, ditandai dengan lebar pita yang cenderung sama.

### Plot ACF

```{r}
acf(stas)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut cenderung *tails off* dan membentuk gelombang sinus.

### Uji ADF

```{r}
tseries::adf.test(stas)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01 yang lebih kecil dari taraf nyata 5% sehingga tolak $H_0$ dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF.

### Plot Box-Cox

```{r}
index <- seq(1:200)
bc = boxcox(stas~index, lambda = seq(0,4,by=0.01))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

Gambar di atas menunjukkan nilai *rounded value* ($\lambda$) optimum sebesar **1,97** dan pada selang kepercayaan 95% nilai memiliki batas bawah **0,22** dan batas atas **3,73**. Selang tersebut memuat nilai satu sehingga dapat dikatakan bahwa data bangkitan stasioner dalam ragam.

### Partisi Data

#### Bagian 1

```{r}
dt_stas1 <- stas[1:67] |> ts()
mean(dt_stas1)
var(dt_stas1)
```

#### Plot Time Series

```{r}
dt_stas1 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Plot deret waktu di atas menunjukkan bahwa data stasioner dalam rataan, ditandai dengan data yang menyebar di sekitar nilai tengahnya (18) dan stasioner dalam ragam, ditandai dengan lebar pita yang cenderung sama.

#### Plot ACF

```{r}
acf(dt_stas1)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut cenderung *tails off* dan membentuk gelombang sinus.

#### Uji ADF

```{r}
tseries::adf.test(dt_stas1)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.043 yang lebih kecil dari taraf nyata 5% sehingga tolak $H_0$ dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF.

#### Plot Boxcox

```{r}
index <- seq(1:67)
bc = boxcox(dt_stas1~index, lambda = seq(-2,6,by=1))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

Gambar di atas menunjukkan nilai *rounded value* ($\lambda$) optimum sebesar **2,2** dan pada selang kepercayaan 95% nilai memiliki batas bawah **-1,03** dan batas atas **5,52**. Selang tersebut memuat nilai satu sehingga dapat dikatakan bahwa data bangkitan stasioner dalam ragam.

#### Bagian 2

```{r}
dt_stas2 <- stas[1:134] |> ts()
mean(dt_stas2)
var(dt_stas2)
```

#### Plot Time Series

```{r}
dt_stas2 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Plot deret waktu di atas menunjukkan bahwa data stasioner dalam rataan, ditandai dengan data yang menyebar di sekitar nilai tengahnya (18) dan stasioner dalam ragam, ditandai dengan lebar pita yang cenderung sama.

#### Plot ACF

```{r}
acf(dt_stas2)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut cenderung *tails off* dan membentuk gelombang sinus.

#### Uji ADF

```{r}
adf.test(dt_stas2)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01 yang lebih kecil dari taraf nyata 5% sehingga tolak $H_0$ dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF.

#### Plot Boxcox

```{r}
index <- seq(1:134)
bc = boxcox(dt_stas2~index, lambda = seq(0,6,by=1))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

Gambar di atas menunjukkan nilai *rounded value* ($\lambda$) optimum sebesar **2,85** dan pada selang kepercayaan 95% nilai memiliki batas bawah **0,48** dan batas atas **5,27**. Selang tersebut memuat nilai satu sehingga dapat dikatakan bahwa data bangkitan stasioner dalam ragam.

## Tidak Stasioner dalam Rataan, Stasioner dalam Ragam

Bagaimana cara mensimulasikan data dengan tren tertentu?

Kunci dari simulasi tersebut berada di $Y_{t}-Y_{t-1}$, atau *first difference*, atau selisih antara observasi di waktu ke $t$ dan observasi sebelumnya. Jika suatu deret waktu memiliki tren naik, misal, maka selisih tersebut akan positif. Sebaliknya, jika suatu deret memiliki tren turun, maka selisih akan negatif. Jika suatu deret stasioner, selisih akan memiliki rata-rata nol.

Ini dapat diilustrasikan dengan fungsi `cumsum`. `cumsum` adalah jumlah kumulatif. Untuk mengerti logika dari pengunaan jumlah kumulatif, bayangkan ada deret waktu dengan nilai awal $c$:

$$
Y_1 = c
$$

Lalu definsikan $d_i$, di mana $i = 2, 3, \ldots$ sebagai selisih observasi ke-i dengan observasi sebelumnya:

$$
d_i = Y_i-Y_{i-1}
$$

Perhatikan bahwa:

$$
\begin{aligned}
Y_3-Y_{1} & = d_3+d_2\\
&= Y_3-Y_2+Y_2-Y_1
\end{aligned}
$$

Cukup jelas bahwa sifat tersebut berarti:

$$
\begin{aligned}
Y_t-Y_1 &= \sum_{i=2}^t d_i\\
Y_t &= Y_1 + \sum_{i=2}^t d_i
\end{aligned}
$$

Atau, amatan di waktu ke $t$ dapat ditemukan dari menambahkan amatan ke-1 dengan jumlah kumulatif perbedaan $d_i$ sampai di waktu ke-t. Kode di bawah membuat data dengan proses tersebut. Ada tiga skenario, yaitu:

1.  Selisih antara observasi dan observasi sebelumnya nol

2.  Selisih antara observasi dan observasi sebelumnya positif

3.  Selisih antara observasi dan observasi sebelumnya negatif

Dengan nilai awal 1 dan komponen $e_t$ menyebar normal.

```{r}
notrend <- 1 + cumsum(rep(0, 100)) + rnorm(100) |> ts()
postrend <- 1 + cumsum(rep(0.2, 100)) + rnorm(100) |> ts() 
negtrend <- 1 + cumsum(rep(-0.2, 100)) + rnorm(100) |> ts()
```

Hasil yang muncul dapat di-plot (note, untuk plotting ini digunakan `ggplot2`; `ts.plot()` dapat digunakan - ini tergantung preferensi saja):

```{r}
plot_notrend <- notrend |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai") + ggtitle("First Difference = 0")
plot_postrend <- postrend |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai") + ggtitle("First Difference = 0.2")
plot_negtrend <- negtrend |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai") + ggtitle("First Difference = -0.2")

ggpubr::ggarrange(plot_notrend, plot_postrend, plot_negtrend, nrow = 3)
```

Dapat disimulasikan proses MA atau AR yang tidak stasioner dengan suatu tren dengan mensimulasikan beda terlebih dahulu (menggunakan `arima.sim`), ditambah suatu konstanta, lalu mencari jumlah kumulatif. Terdapat juga parameter `mean` di fungsi `arima.sim`, tetapi parameter ini adalah parameter untuk $E[e_t]$, bukan $E[Y_t-Y_{t-1}]$. Proses dari nilai harapan *white noise* tertentu menjadi nilai harapan $Y$ di suatu proses MA atau AR yang tak stasioner sangat tergantung pada model, yang diilustrasikan [di sini](https://stats.stackexchange.com/questions/294748/arima-sim-again-what-does-the-mean-parameter-do-in-an-ma1-sim/).

```{r}
startSpot <- 3
dt <- {arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), sd=2) + 1.5}  |> ts()
yt <- startSpot + cumsum(dt) |> ts()

dt_alt <- arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), mean = 1.5, sd=2)  |> ts()
yt_alt <- startSpot + cumsum(dt_alt) |> ts()

plot_dt <- dt |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai") + ggtitle("Penambahan konstanta 1.5 di selisih")
plot_yt <- yt |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
plot_dt_alt <- dt_alt |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai") + ggtitle("Mean 1.5 di parameter arima.sim")
plot_yt_alt <- yt_alt |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) + geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")

ggpubr::ggarrange(plot_dt, plot_yt, plot_dt_alt, plot_yt_alt)
```

Terlihat di contoh di atas bahwa menambahkan konstanta 1.5 pada hasil `arima.sim` beda dengan memasukkan parameter `mean = 1.5`.

### Data Bangkitan Baru

```{r}
set.seed(8990)
dt_alt <- arima.sim(n=200, list(order=c(1,0,1),ar=c(.2), ma=.2), mean=0.2, sd=0.5)  |> ts()
postrend <- startSpot + cumsum(dt_alt) |> ts()
```

### Plot Time Series

```{r}
postrend |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
mean(postrend)
var(postrend)
```

Berdasarkan plot time series tersebut, terlihat bahwa data tidak stasioner dalam rataan, ditandai dengan adanya tren positif, tetapi stasioner dalam ragam, ditandai dengan adanya lebar pita pada plot yang cenderung sama.

```{r}
ts.plot(diff(postrend))
```

### Plot ACF

```{r}
acf(postrend)
```

### Uji ADF

```{r}
adf.test(postrend)
```

### Plot Box-Cox

```{r}
index <- seq(1:200)
bc = boxcox(postrend~index, lambda = seq(0.8,1.1,by=0.001))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

### Partisi Data

#### Bagian 1

```{r}
postrend1 <- postrend[1:100] |> ts()
mean(postrend1)
var(postrend1)
```

#### Plot Time Series

```{r}
postrend1 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line()+theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

#### Plot ACF

```{r}
acf(postrend1)
```

#### Uji ADF

```{r}
adf.test(postrend1)
```

#### Plot Boxcox

```{r}
index <- seq(1:100)
bc = boxcox(postrend1~index, lambda = seq(0.5,1,by=0.001))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

#### Bagian 2

```{r}
postrend2 <- postrend[101:200] |> ts()
mean(postrend2)
var(postrend2)
```

#### Plot Time Series

```{r}
postrend2 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

#### Plot ACF

```{r}
acf(postrend2)
```

#### Uji ADF

```{r}
adf.test(postrend2)
```

#### Plot Boxcox

```{r}
index <- seq(1:100)
bc = boxcox(postrend2~index, lambda = seq(-1,1.2,by=0.001))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

## Tidak Stasioner dalam Ragam, Stasioner dalam Rataan

`arima.sim` memiliki parameter sd yang dapat di-set beda.

```{r}
set.seed(9089)
sd1 <- arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), sd = 1)
sd5 <- arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), sd = 5)
dtgab <- c(sd1,sd5) |> ts()
```

### Plot Time Series

```{r}
dtgab |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data stasioner dalam rataan, ditandai dengan tidak adanya trend ataupun musiman pada data, namun tidak stasioner dalam ragam, ditandai dengan adanya perbedaan lebar pita pada plot

### Plot ACF

```{r}
acf(dtgab)
```

Berdasarkan plot ACF, terlihat bahwa data stasioner dalam rataan, ditandai dengan plot ACF yang *tails off* dan cenderung membentuk gelombang sinus

### Uji ADF

```{r}
adf.test(dtgab)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01 yang kurang dari taraf nyata 5% dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

### Partisi Data

#### Bagian 1

```{r}
dtgab1 <- dtgab[1:66] |> ts()
mean(dtgab1)
var(dtgab1)
```

#### Plot Time Series

```{r}
dtgab1 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data cenderung stasioner dalam rataan, ditandain dengan tidak adanya trend dan musiman pada data, serta stasioner dalam ragam, ditandai dengan lebar pita yang cenderung sama pada plot tersebut

#### Plot ACF

```{r}
acf(dtgab1)
```

Berdasarkan plot ACF, terlihat bahwa data cenderung stasioner dalam rataan ditandai dengan plot ACF yang *tails off* dan cenderung membentuk gelombang sinus

#### Uji ADF

```{r}
adf.test(dtgab1)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01691 yang kurang dari taraf nyata 5% dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

#### Plot Boxcox

#### Bagian 2

```{r}
dtgab2 <- dtgab[1:132] |> ts()
mean(dtgab2)
var(dtgab2)
```

#### Plot Time Series

```{r}
dtgab2 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot data deret waktu tersebut, terlihat bahwa data stasioner dalam rataan, ditandai dengan data yang tidak menunjukkan adanya trend ataupun musiman, serta tidak stasioner dalam ragam ditandai dengan lebar pita pada plot yang cenderung berbeda di beberapa periode waktunya

#### Plot ACF

```{r}
acf(dtgab2)
```

Berdasarkan plot ACF tersebut, terlihat bahwa data stasioner dalam rataan ditandai dengan plot ACF yang *cuts off* pada lag ke 2

#### Uji ADF

```{r}
adf.test(dtgab2)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01383 yang kurang dari taraf nyata 5% dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

## Tidak Stasioner dalam Rataan dan Ragam

Hal ini dapat disimulasikan dengan membangkitkan data yang tidak stasioner dalam ragam lalu membentuk trend menggunakan data tersebut

```{r}
set.seed(8990)
sd2 <- arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), sd = 2)
sd6 <- arima.sim(n=100, list(order=c(1,0,1),ar=c(.2), ma=.2), sd = 6)
datagab <- c(sd2,sd6)
dt_rg <- startSpot + cumsum(datagab) |> ts() 
```

### Plot Time Series

```{r}
dt_rg |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data tidak stasioner dalam rataan, ditandai dengan adanya trend pada data dan tidak stasioner dalam ragam, ditandai dengan adanya perbedaan lebar pita pada plot

### Plot ACF

```{r}
acf(dt_rg)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut menurun secara perlahan (*tails off slowly*) yang menandakan data tidak stasioner dalam rataan

### Uji ADF

```{r}
adf.test(dt_rg)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.6447 yang lebih besar dari taraf nyata 5% dan menandakan bahwa data tidak stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

### Partisi Data

#### Bagian 1

```{r}
dt_rg1 <- dt_rg[1:66] |> ts()
mean(dt_rg1)
var(dt_rg1)
```

#### Plot Time Series

```{r}
dt_rg1 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data tidak stasioner dalam rataan karena masih terdapat tren pada data, namun cenderung stasioner dalam ragam karena memiliki lebar pita yang cenderung sama

#### Plot ACF

```{r}
acf(dt_rg1)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut menurun secara perlahan (*tails off slowly*) yang menandakan data tidak stasioner dalam rataan

#### Uji ADF

```{r}
adf.test(dt_rg1)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.6816 yang lebih besar dari taraf nyata 5% dan menandakan bahwa data tidak stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

#### Bagian 2

```{r}
dt_rg2 <- dt_rg[67:132] |> ts()
mean(dt_rg2)
var(dt_rg2)
```

#### Plot Time Series

```{r}
dt_rg2 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data tidak stasioner dalam rataan karena masih terdapat tren pada data, dan tidak stasioner dalam ragam karena memiliki lebar pita yang cenderung tidak sama

#### Plot ACF

```{r}
acf(dt_rg2)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut menurun secara perlahan (*tails off slowly*) yang menandakan data tidak stasioner dalam rataan

#### Uji ADF

```{r}
adf.test(dt_rg2)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.9202 yang lebih besar dari taraf nyata 5% dan menandakan bahwa data tidak stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF

#### Bagian 3

```{r}
dt_rg3 <- dt_rg[133:200] |> ts()
mean(dt_rg3)
var(dt_rg3)
```

#### Plot Time Series

```{r}
dt_rg3 |> as_tsibble() |> 
  ggplot(aes(x = index, y = value)) +
  geom_line() + theme_bw() +
  xlab("Obs") + ylab("Nilai")
```

Berdasarkan plot time series tersebut, terlihat bahwa data tidak stasioner dalam rataan karena masih terdapat tren pada data, namun cenderung stasioner dalam ragam karena memiliki lebar pita yang cenderung sama

#### Plot ACF

```{r}
acf(dt_rg3)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF pada data tersebut menurun secara perlahan (*tails off slowly*)yang menandakan data tidak stasioner dalam rataan

#### Uji ADF

```{r}
tseries::adf.test(dt_rg3,k=5)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.323 yang lebih besar dari taraf nyata 5% dan menandakan bahwa data tidak stasioner dalam rataan. Hal ini tidak sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF


PERT 6
---
title: "Pertemuan 67"
author: "Adisti Suci Rahmah"
date: "2023-10-02"
output: html_document
---

---
title: "Pendugaan Parameter, Diagnostik Model, dan Peramalan"
output:
  html_document: default
  pdf_document: default
date: "2023-09-30"
---

## Packages

```{r}
library(ggplot2)
library(tsibble)
library(tseries)
library(MASS)
library(forecast)
library(TSA)
library(TTR)
library(aTSA)
library(graphics)
```

## Data Bangkitan

### Pembangkitan Data

Data yang akan dibangkitkan adalah data dengan model MA(2) sebagai berikut.

```{r}
set.seed(99)
ma2 <- arima.sim(list(order = c(0,0,2), ma = c(0.55,0.65)), n = 175)
```

Data kemudian dibagi menjadi data latih dan data uji. Pembagian kali ini dilakukan dengan proporsi / perbandingan, yaitu 80:20.

```{r}
ma2 <- ma2[-c(1:25)]
ma2.train <- ma2[1:120]
ma2.test <- ma2[121:150]
```

### Eksplorasi Data

Sebelum masuk dalam tahap pemodelan, dilakukan eksplorasi data dengan plot deret waktu untuk melihat pola data.

```{r}
#--PLOT TIME SERIES--#
plot(ma2.train,
     col = "navyblue",
     lwd = 1,
     type = "o",
     xlab = "Time",
     ylab = "Data")
```

Berdasarkan plot data deret waktu di atas, terlihat data cenderung stasioner dalam rataan dan ragam. Data stasioner dalam rataan karena menyebar/bergerak di sekitar nilai tengahnya (0) dan dikatakan stasioner dalam ragam karena memiliki lebar pita yang cenderung sama. Selain dengan plot data deret waktu, akan dilakukan pengecekan stasioneritas data dengan plot ACF dan uji ADF.

```{r}
#--CEK KESTASIONERAN---#
acf(ma2.train, main="ACF", lag.max=20)
```

Berdasarkan plot ACF di atas, dapat dilihat bahwa plot *cuts off* pada *lag* ke-2. Hal ini sesuai dengan proses pembangkitan model MA(2).

```{r}
adf.test(ma2.train) 
#stasioner
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01358 yang lebih kecil dari taraf nyata 5% sehingga tolak $H_0$ dan menandakan bahwa data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF.

### Spesifikasi Model

```{r}
#---SPESIFIKASI MODEL---#
par(mfrow = c(1,2))
acf(ma2.train, main="ACF", lag.max=20) #ARIMA(0,0,2)
pacf(ma2.train, main="PACF", lag.max=20) #ARIMA(1,0,0)
par(mfrow = c(1,1))
```

Berdasarkan Plot ACF, terlihat *cuts off* pada lag ke-2 sehingga dapat kita asumsikan model yang terbentuk adalah ARIMA(0,0,2). Selanjutnya, berdasarkan plot PACF, terlihat *cuts off* pada lag pertama sehingga model yang terbentuk adalah ARIMA(1,0,0). Selain dengan plot ACF dan PACF, penentuan spesifikasi model dilakukan dengan *extended ACF* (EACF) berikut ini.

```{r}
eacf(ma2.train) 
#ARIMA(0,0,2) #ARIMA(1,0,3) #ARIMA(2,0,3) #ARIMA(3,0,3) 
#Terdapat 5 model tentatif
```

Menggunakan plot EACF, dapat diambil beberapa model dengan melihat ujung segitiga yang terbentuk, antara lain ARIMA(0,0,2), ARIMA(1,0,3), ARIMA(2,0,3), dan ARIMA(3,0,3).

### Pendugaan Parameter

Selanjutnya akan dilakukan pendugaan parameter kelima model ARIMA yang terbentuk sebelumnya. Pendugaan dilakukan dengan fungsi `Arima()` yang dilanjutkan dengan melihat nilai AIC pada ringkasan data dan melihat signifikansi parameter.

```{r}
#---PENDUGAAN PARAMETER MODEL---#
model1.ma2=Arima(ma2.train, order=c(0,0,2),method="ML")
summary(model1.ma2) #AIC=326.87
lmtest::coeftest(model1.ma2) #seluruh parameter signifikan

model2.ma2=Arima(ma2.train, order=c(1,0,0),method="ML") 
summary(model2.ma2) #AIC=340.47
lmtest::coeftest(model2.ma2) #seluruh parameter signifikan

model3.ma2=Arima(ma2.train, order=c(1,0,3),method="ML") 
summary(model3.ma2) #AIC=329.22
lmtest::coeftest(model3.ma2) #tidak ada yang signifikan

model4.ma2=Arima(ma2.train, order=c(2,0,3),method="ML") 
summary(model4.ma2) #AIC=330.6
lmtest::coeftest(model4.ma2) #hanya ma2 yang signifikan

model5.ma2=Arima(ma2.train, order=c(3,0,3),method="ML") 
summary(model5.ma2) #AIC=329.87
lmtest::coeftest(model5.ma2) #hanya ma1 dan ma2 yang signifikan

#model yang dipilih adalah model 1, yaitu ARIMA(0,0,2)
```

Berdasarkan pendugaan parameter di atas, nilai AIC terkecil dimiliki oleh model ARIMA(0,0,2) dan parameter model ARIMA(0,0,2) juga seluruhnya signifikan sehingga model yang dipilih adalah model ARIMA(0,0,2).

### Analisis Sisaan

Model terbaik hasil identifikasi kemudian dicek asumsi sisaannya. Sisaan model ARIMA harus memenuhi asumsi normalitas, kebebasan, dan kehomogenan ragam. Diagnostik model dilakukan secara eksplorasi dan uji formal.

#### Eksplorasi Sisaan

```{r}
#Eksplorasi
sisaan.ma2 <- model1.ma2$residuals
par(mfrow=c(2,2))
qqnorm(sisaan.ma2)
qqline(sisaan.ma2, col = "blue", lwd = 2)
plot(c(1:length(sisaan.ma2)),sisaan.ma2)
acf(sisaan.ma2)
pacf(sisaan.ma2)
par(mfrow = c(1,1))
```

Berdasarkan plot kuantil-kuantil normal, secara eksplorasi ditunjukkan sisaan menyebar normal mengikuti garis $45^{\circ}$. Kemudian dapat dilihat juga lebar pita sisaan yang cenderung sama menandakan bahwa sisaan memiliki ragam yang homogen. Akan tetapi, plot ACF dan PACF sisaan ARIMA(0,0,2) signifikan pada lag ke-6 sehingga sisaan tidak saling bebas. Kondisi ini akan diuji lebih lanjut dengan uji formal.

#### Uji Formal

```{r}
#1) Sisaan Menyebar Normal
ks.test(sisaan.ma2,"pnorm") 
#tak tolak H0 > sisaan menyebar normal
```

Selain dengan eksplorasi, asumsi tersebut dapat diuji menggunakan uji formal. Pada tahapan ini uji formal yang digunakan untuk normalitas adalah uji Kolmogorov-Smirnov (KS). Hipotesis pada uji KS adalah sebagai berikut.

$H_0$ : Sisaan menyebar normal

$H_1$ : Sisaan tidak menyebar normal

Berdasarkan uji KS tersebut, didapat *p-value* sebesar 0.9788 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa sisaan menyebar normal. Hal ini sesuai dengan hasil eksplorasi menggunakan plot kuantil-kuantil normal.

```{r}
#2) Sisaan saling bebas/tidak ada autokorelasi
Box.test(sisaan.ma2, type = "Ljung") 
#tak tolak H0 > sisaan saling bebas
```

Selanjutnya akan dilakukan uji formal untuk kebebasan sisaan menggunakan uji Ljung-Box. Hipotesis yang digunakan adalah sebagai berikut.

$H_0$ : Sisaan saling bebas

$H_1$ : Sisaan tidak tidak saling bebas

Berdasarkan uji Ljung-Box tersebut, didapat *p-value* sebesar 0.5082 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa sisaan saling bebas. Hal ini berbeda dengan eksplorasi.

```{r}
#3) Sisaan homogen
Box.test((sisaan.ma2)^2, type = "Ljung") 
#tak tolak H0 > sisaan homogen
```

Hipotesis yang digunakan untuk uji kehomogenan ragam adalah sebagai berikut.

$H_0$ : Ragam sisaan homogen

$H_1$ : Ragam sisaan tidak homogen

Berdasarkan uji Ljung-Box terhadap sisaan kuadrat tersebut, didapat *p-value* sebesar 0.116 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa ragam sisaan homogen.

```{r}
#4) Nilai tengah sisaan sama dengan nol
t.test(sisaan.ma2, mu = 0, conf.level = 0.95) 
#tak tolak h0 > nilai tengah sisaan sama dengan 0
```

Terakhir, dengan uji-t, akan dicek apakah nilai tengah sisaan sama dengan nol. Hipotesis yang diujikan sebagai berikut.

$H_0$ : nilai tengah sisaan sama dengan 0

$H_1$ : nilai tengah sisaan tidak sama dengan 0

Berdasarkan uji-ttersebut, didapat *p-value* sebesar 0.9594 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa nilai tengah sisaan sama dengan nol. Hal ini berbeda dengan eksplorasi.

### Overfitting

Tahapan selanjutnya adalah *overfitting* dilakukan dengan menaikkan orde AR(p) dan MA(q) dari model ARIMA(0,0,2) untuk melihat apakah terdapat model lain yang lebih baik dari model saat ini. Kandidat model *overfitting* adalah ARIMA(1,0,2) dan ARIMA(0,0,3).

```{r}
#---OVERFITTING---#
model1a.ma2=Arima(ma2.train, order=c(1,0,2),method="ML")
summary(model1a.ma2) #327.31
lmtest::coeftest(model1a.ma2) #ar1 tidak signifikan

model1b.ma2=Arima(ma2.train, order=c(0,0,3),method="ML")
summary(model1b.ma2) #327.24
lmtest::coeftest(model1b.ma2) #ma3 tidak signifikan

#model yang dipilih adalah model awal, yaitu ARIMA(0,0,2)
```

Berdasarkan kedua model hasil *overfitting* di atas, model ARIMA(1,0,2) dan ARIMA(0,0,3) memiliki AIC yang lebih besar dibandingkan dengan model ARIMA(0,0,2) dan parameter kedua model ARIMA(1,0,2) dan ARIMA(0,0,3) tidak seluruhnya signifikan. Oleh karena itu, model ARIMA(0,0,2) akan tetap digunakan untuk melakukan peramalan.

### Peramalan

Peramalan dilakukan menggunakan fungsi `forecast()` . Contoh peramalan berikut ini dilakukan untuk 30 hari ke depan.

```{r}
#---FORECAST---#
ramalan <- forecast::forecast(model1.ma2, h = 30) 
ramalan
data.ramalan <- ramalan$mean
plot(ramalan)
```

Berdasarkan hasil plot ramalan di atas, dapat dilihat bahwa ramalan ARIMA(0,0,2) cenderung meningkat di awal periode dan stabil hingga akhir periode. Selanjutnya, dapat dicari nilai akurasi antara hasil ramalan dengan data uji sebagai berikut.

```{r}
perbandingan<-matrix(data=c(ma2.test, data.ramalan),
                     nrow = 30, ncol = 2)
colnames(perbandingan)<-c("Aktual","Hasil Forecast")
perbandingan
accuracy(data.ramalan, ma2.test)
```

## Data Asli

Digunakan data kurs yang dalam hal ini hanya digunakan data 500 periode awal

```{r}
datakurs<-read.csv("D:\\S1 STATISTIKA\\SEMESTER 5\\MPDW\\mpdw\\praktikum\\kurs.csv",header=T)
datakurs <- datakurs[1:500,]
datakurs.ts<-ts(datakurs)
```

### Eksplorasi Data

#### Plot Data Penuh

```{r}
plot.ts(datakurs.ts, lty=1, xlab="waktu", ylab="Kurs", main="Plot Data Kurs")
```

Berdasarkan plot data deret waktu, terlihat bahwa data cenderung memiliki trend yang naik. Berdasarkan pola data, pembagian data latih dan data uji ditetapkan dengan proporsi 86%:14%.

#### Plot Data Latih

```{r}
kurstrain<-datakurs[1:430]
train.ts<-ts(kurstrain)
plot.ts(train.ts, lty=1, xlab="waktu", ylab="Kurs", main="Plot Kurs Train")
```

Berdasarkan plot data deret waktu pada data latih, terlihat bahwa data cenderung memiliki trend yang naik dan cenderung tidak bergerak pada nilai tengah tertentu. Hal ini mengindikasikan bahwa data tidak stasioner dalam rataan.

#### Plot Data Uji

```{r}
kurstest<-datakurs[431:500]
test.ts<-ts(kurstest)
plot.ts(test.ts, lty=1, xlab="waktu", ylab="Kurs", main="Plot Kurs Test")
```

### Uji Stasioneritas Data

#### Plot ACF

```{r}
acf(train.ts)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF data menurun secara perlahan (*tails of slowly*). Hal ini juga menjadi indikasi bahwa data tidak stasioner dalam rataan

#### Uji ADF

```{r}
tseries::adf.test(train.ts)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.5553 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa data tidak stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF, sehingga ketidakstasioneran model kedepannya harus ditangani

#### Plot Box-Cox

```{r}
index <- seq(1:430)
bc = boxcox(train.ts~index, lambda = seq(5,10,by=1))
#Nilai Rounded Lambda
lambda <- bc$x[which.max(bc$y)]
lambda
#SK
bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)]
```

Plot Boxcox menunjukkan nilai *rounded value* ($\lambda$) optimum sebesar **6,64** dan pada selang kepercayaan 95% nilai memiliki batas bawah **0,48** dan batas atas **5,27**. Selang tersebut memuat nilai satu sehingga dapat dikatakan bahwa data bangkitan stasioner dalam ragam.

### Penanganan Ketidakstasioneran Data

```{r}
train.diff<-diff(train.ts,differences = 1) 
plot.ts(train.diff, lty=1, xlab="waktu", ylab="Data Difference 1 Kurs", main="Plot Difference Kurs")
```

Berdasarkan plot data deret waktu, terlihat bahwa data sudah stasioner dalam rataan ditandai dengan data bergerak pada nilai tengah tertentu (tidak terdapat trend ataupun musiman pada data)

#### Plot ACF

```{r}
acf(train.diff)
```

Berdasarkan plot tersebut, terlihat bahwa plot ACF cuts off pada lag ke 1. Hal ini menandakan data sudah stasioner dalam rataan dan ketidakstasioneran data telah berhasil tertangani.

#### Uji ADF

```{r}
tseries::adf.test(train.diff)
```

$H_0$ : Data tidak stasioner dalam rataan

$H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, didapat *p-value* sebesar 0.01 yang lebih kecil dari taraf nyata 5% sehingga tolak $H_0$ atau data stasioner dalam rataan. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF, sehingga dalam hal ini ketidakstasioneran data sudah berhasil ditangani dan dapat dilanjutkan ke pemodelan

### Identifikasi Model

#### Plot ACF

```{r}
acf(train.diff)
```

Berdasarkan plot tersebut, terlihat bahwa plot ACF cenderung *cuts off* pada lag ke 1, sehingga jika plot PACF dianggap *tails of*, maka model tentatifnya adalah ARIMA(0,1,1).

#### Plot PACF

```{r}
pacf(train.diff)
```

Berdasarkan plot tersebut, terlihat bahwa plot PACF cenderung *cuts off* pada lag ke 1, sehingga jika plot ACF dianggap *tails of*, maka model tentatifnya adalah ARIMA(1,1,0).

Jika baik plot ACF maupun plot PACF keduanya dianggap tails of, maka model yang terbentuk adalah ARIMA(1,1,1)

#### Plot EACF

```{r}
eacf(train.diff)
```

Identifikasi model menggunakan plot EACF dilakukan dengan melihat ujung segitiga pada pola segitiga nol. Dalam hal ini model tentatif yang terbentuk adalah ARIMA(0,1,2), ARIMA(1,1,2), ARIMA(2,1,2), dan ARIMA(3,1,2).

### Pendugaan Parameter Model Tentatif

#### ARIMA(0,1,1)

```{r}
model1.da=Arima(train.diff, order=c(0,1,1),method="ML")
summary(model1.da) #AIC=4753.18
lmtest::coeftest(model1.da) #seluruh parameter signifikan
```

#### ARIMA(1,1,0)

```{r}
model2.da=Arima(train.diff, order=c(1,1,0),method="ML")
summary(model2.da) #AIC=4917.41
lmtest::coeftest(model2.da) #seluruh parameter signifikan
```

#### ARIMA(1,1,1)

```{r}
model3.da=Arima(train.diff, order=c(1,1,1),method="ML")
summary(model3.da) #AIC=4761.39
lmtest::coeftest(model3.da) #seluruh parameter signifikan
```

#### ARIMA(0,1,2)

```{r}
model4.da=Arima(train.diff, order=c(0,1,2),method="ML")
summary(model4.da) #AIC=4748.3
lmtest::coeftest(model4.da) #seluruh parameter signifikan
```

#### ARIMA(1,1,2)

```{r}
model5.da=Arima(train.diff, order=c(1,1,2),method="ML")
summary(model5.da) #AIC=4749.85 
lmtest::coeftest(model5.da) #terdapat parameter tidak signifikan
```

#### ARIMA(2,1,2)

```{r}
model6.da=Arima(train.diff, order=c(2,1,2),method="ML")
summary(model6.da) #AIC=4749.52
lmtest::coeftest(model6.da) #terdapat parameter tidak signifikan
```

Berdasarkan pendugaan parameter di atas, nilai AIC terkecil dimiliki oleh model ARIMA(0,1,2) dan parameter model ARIMA(0,1,2) juga seluruhnya signifikan sehingga model yang dipilih adalah model ARIMA(0,1,2).

### Analisis Sisaan

Model terbaik hasil identifikasi kemudian dicek asumsi sisaannya. Sisaan model ARIMA harus memenuhi asumsi normalitas, kebebasan sisaan, dan kehomogenan ragam. Diagnostik model dilakukan secara eksplorasi dan uji formal.

#### Eksplorasi Sisaan

```{r}
#Eksplorasi 
sisaan.da <- model4.da$residuals 
par(mfrow=c(2,2)) 
qqnorm(sisaan.da) 
qqline(sisaan.da, col = "blue", lwd = 2) 
plot(c(1:length(sisaan.da)),sisaan.da) 
acf(sisaan.da) 
pacf(sisaan.da) 
par(mfrow = c(1,1))
```

Berdasarkan plot kuantil-kuantil normal, secara eksplorasi ditunjukkan sisaan tidak menyebar normal ditandai dengan titik titik yang cenderung tidak mengikuti garis $45^{\circ}$. Kemudian dapat dilihat juga lebar pita sisaan yang cenderung tidak sama menandakan bahwa sisaan memiliki ragam yang heterogen. Plot ACF dan PACF sisaan ARIMA(0,0,2) juga tidak signifikan pada 20 lag awal yang menandakan saling bebas. Kondisi ini akan diuji lebih lanjut dengan uji formal.

#### Uji Formal

```{r}
#1) Sisaan Menyebar Normal 
ks.test(sisaan.da,"pnorm")  #tak tolak H0 > sisaan menyebar normal
```

Selain dengan eksplorasi, asumsi tersebut dapat diuji menggunakan uji formal. Pada tahapan ini uji formal yang digunakan untuk normalitas adalah uji Kolmogorov-Smirnov (KS). Hipotesis pada uji KS adalah sebagai berikut.

$H_0$ : Sisaan menyebar normal

$H_1$ : Sisaan tidak menyebar normal

Berdasarkan uji KS tersebut, didapat *p-value* sebesar 0.00 yang kurang dari taraf nyata 5% sehingga tolak $H_0$ dan menandakan bahwa sisaan tidak menyebar normal. Hal ini sesuai dengan hasil eksplorasi menggunakan plot kuantil-kuantil normal.

```{r}
#2) Sisaan saling bebas/tidak ada autokorelasi 
Box.test(sisaan.da, type = "Ljung")  #tak tolak H0 > sisaan saling bebas
```

Selanjutnya akan dilakukan uji formal untuk kebebasan sisaan menggunakan uji Ljung-Box. Hipotesis yang digunakan adalah sebagai berikut.

$H_0$ : Sisaan saling bebas

$H_1$ : Sisaan tidak tidak saling bebas

Berdasarkan uji Ljung-Box tersebut, didapat *p-value* sebesar 0.8471 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa sisaan saling bebas. Hal ini berbeda dengan eksplorasi.

```{r}
#3) Sisaan homogen 
Box.test((sisaan.da)^2, type = "Ljung")  #tak tolak H0 > sisaan homogen
```

Hipotesis yang digunakan untuk uji kehomogenan ragam adalah sebagai berikut.

$H_0$ : Ragam sisaan homogen

$H_1$ : Ragam sisaan tidak homogen

Berdasarkan uji Ljung-Box terhadap sisaan kuadrat tersebut, didapat *p-value* sebesar 0.000 yang kurang dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa ragam sisaan tidak homogen.

```{r}
#4) Nilai tengah sisaan sama dengan nol 
t.test(sisaan.da, mu = 0, conf.level = 0.95)  #tak tolak h0 > nilai tengah sisaan sama dengan 0
```

Terakhir, dengan uji-t, akan dicek apakah nilai tengah sisaan sama dengan nol. Hipotesis yang diujikan sebagai berikut.

$H_0$ : nilai tengah sisaan sama dengan 0

$H_1$ : nilai tengah sisaan tidak sama dengan 0

Berdasarkan uji-ttersebut, didapat *p-value* sebesar 0.4866 yang lebih besar dari taraf nyata 5% sehingga tak tolak $H_0$ dan menandakan bahwa nilai tengah sisaan sama dengan nol. Hal ini berbeda dengan eksplorasi.

### Peramalan

Peramalan dilakukan menggunakan fungsi `forecast()` . Contoh peramalan berikut ini dilakukan untuk 30 hari ke depan.

```{r}
#---FORECAST---#
ramalan.da <- forecast::forecast(model4.da, h = 30) 
ramalan.da
data.ramalan.da <- ramalan.da$mean
plot(ramalan.da)
```

Berdasarkan hasil plot ramalan di atas, dapat dilihat bahwa ramalan ARIMA(0,012) cenderung stabil hingga akhir periode. Selanjutnya, dapat dicari nilai akurasi antara hasil ramalan dengan data uji sebagai berikut.

```{r}
pt_1 <- train.ts[430] #nilai akhir data latih
hasil.forc.Diff <- data.ramalan.da
hasil <- diffinv(hasil.forc.Diff, differences = 1) + pt_1
#has.1 sama hasilnta dengan: cumsum(c(pt_1,hasil.forc.Diff))
ts.plot(train.ts,hasil)
```

```{r}
perbandingan.da<-matrix(data=c(head(test.ts, n=30), hasil[-1]),
                     nrow = 30, ncol = 2)
colnames(perbandingan.da)<-c("Aktual","Hasil Forecast")
perbandingan.da
accuracy(ts(hasil[-1]), head(test.ts, n=30))
```





